llm:
  provider: "openai" #"openai" #"ollama"
  model_id: "gemini-2.5-flash-preview-04-17" #"deepseek-chat" #"ollama_chat/qwen3:32b" #ollama_chat/qwen3:14b #"gemini-2.0-flash" #"ollama_chat/qwen3:32b" #Qwen/Qwen3-14B" #ollama_chat/qwen3:14b
  provider_kwargs:
    transformers:
      device_map: "auto" # Example
      # torch_dtype: "auto" # Example
      max_new_tokens: 128000
    ollama:
        # torch_dtype: "auto" # Example
        api_base: "http://localhost:11434"
        num_ctx: 128000
    openai:
      max_new_tokens: 32768
      api_base: "https://generativelanguage.googleapis.com/v1beta/openai/" #"https://api.deepseek.com" # "https://generativelanguage.googleapis.com/v1beta/openai/" # https://willma.liza.surf.nl/api/v0
      api_key: "GEMINI_API_KEY" # "DEEPSEEK_API_KEY" # 

agent:
  max_steps: 50
  stream_outputs: true
  additional_authorized_imports:
    - "torch"
    - "numpy"
    - "numpy.*"
    - "pandas"
    - "os"
    - "json"
    - "logging"
    - "posixpath"
    - "open"
    - "sklearn"
    - "matplotlib"
    - "matplotlib.*"
    - "PIL"
    - "PIL.*"
    - "glob"
    - "shutil"
    - "logging"
  sub_agents: ["browsing", "pdf_opening", "file_searching", "data_inspecting", "package_installing", "file_managing"] # unused for now
  orchestrator_agents: ["research_orchestrator", "environmentsetup_orchestrator", "dataingestionvalidation_orchestrator", "exploratorydataanalysis_orchestrator", "datapreprocessingfeatureengineering_orchestrator", "modeltraining_orchestrator", "hyperparameteroptimization_orchestrator", "modelevaluation_orchestrator", "reporting_orchestrator"] # orchestrator agent defines which sub agents are needed


run:
  initial_prompt_json: "../configs/initial_project_config.json" # Path to JSON file with initial prompt details
  execute_phase: "all"

